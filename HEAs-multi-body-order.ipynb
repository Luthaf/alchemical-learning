{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cProfile\n",
    "import time\n",
    "\n",
    "import ase.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import torch\n",
    "\n",
    "from utils.combine import CombineRadial, CombineRadialSpecies, CombineSpecies\n",
    "from utils.dataset import AtomisticDataset, create_dataloader\n",
    "from utils.linear import LinearModel\n",
    "from utils.operations import SumStructures, remove_gradient\n",
    "from utils.soap import PowerSpectrum, CompositionFeatures\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "n_train = 400\n",
    "\n",
    "frames = ase.io.read(\"data/data_shuffle.xyz\", f\":{n_test + n_train}\")\n",
    "\n",
    "train_frames = frames[:n_train]\n",
    "test_frames = frames[-n_test:]\n",
    "\n",
    "train_energies = torch.tensor(\n",
    "    [frame.info[\"energy\"] for frame in train_frames]\n",
    ").reshape(-1, 1).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "test_energies = torch.tensor(\n",
    "    [frame.info[\"energy\"] for frame in test_frames]\n",
    ").reshape(-1, 1).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "train_forces = [\n",
    "    torch.tensor(frame.arrays[\"forces\"]).to(dtype=torch.get_default_dtype())\n",
    "    for frame in train_frames\n",
    "]\n",
    "\n",
    "test_forces = [\n",
    "    torch.tensor(frame.arrays[\"forces\"]).to(dtype=torch.get_default_dtype()) \n",
    "    for frame in test_frames\n",
    "]\n",
    "\n",
    "print(f\"using {n_train} training frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = set()\n",
    "for frame in frames:\n",
    "    all_species.update(frame.numbers)\n",
    "\n",
    "all_species = list(map(lambda u: int(u), all_species))\n",
    "\n",
    "# HYPERS_FROM_PAPER = {\n",
    "#     \"interaction_cutoff\": 5.0,\n",
    "#     \"max_angular\": 9,\n",
    "#     \"max_radial\": 12,\n",
    "#     \"gaussian_sigma_constant\": 0.3,\n",
    "#     \"gaussian_sigma_type\": \"Constant\",\n",
    "#     \"cutoff_smooth_width\": 0.5,\n",
    "#     \"radial_basis\": \"GTO\",\n",
    "#     \"compute_gradients\": False,\n",
    "#     \"expansion_by_species_method\": \"user defined\",\n",
    "#     \"global_species\": all_species,\n",
    "# }\n",
    "\n",
    "HYPERS_SMALL = {\n",
    "    \"cutoff\": 4.0,\n",
    "    \"max_angular\": 3,\n",
    "    \"max_radial\": 5,\n",
    "    \"atomic_gaussian_width\": 0.3,\n",
    "    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n",
    "    \"radial_basis\": {\"SplinedGto\": {\"accuracy\": 1e-6}},\n",
    "    \"gradients\": False,\n",
    "    \"center_atom_weight\": 1.0,\n",
    "    # # TODO: implement this in rascaline itself\n",
    "    # \"radial_per_angular\": {\n",
    "    #     # l: n\n",
    "    #     0: 10,\n",
    "    #     1: 8,\n",
    "    #     2: 8,\n",
    "    #     3: 4,\n",
    "    #     4: 4,\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop, energies only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AtomisticDataset(train_frames, all_species, HYPERS_SMALL, train_energies, radial_spectrum_n_max=12)\n",
    "test_dataset = AtomisticDataset(test_frames, all_species, HYPERS_SMALL, test_energies, radial_spectrum_n_max=12)\n",
    "\n",
    "HYPERS_GRAD = copy.deepcopy(HYPERS_SMALL)\n",
    "HYPERS_GRAD[\"gradients\"] = False\n",
    "train_dataset_grad = AtomisticDataset(train_frames, all_species, HYPERS_GRAD, train_energies, train_forces, radial_spectrum_n_max=12)\n",
    "test_dataset_grad = AtomisticDataset(test_frames, all_species, HYPERS_GRAD, test_energies, test_forces, radial_spectrum_n_max=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_no_batch = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=len(train_dataset),\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_single_frame = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_grad = create_dataloader(\n",
    "    train_dataset_grad,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_grad_no_batch = create_dataloader(\n",
    "    train_dataset_grad,\n",
    "    batch_size=len(train_dataset_grad),\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataloader = create_dataloader(\n",
    "    test_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataloader_grad = create_dataloader(\n",
    "    test_dataset_grad,\n",
    "    batch_size=50,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mae(predicted, actual):\n",
    "    return torch.mean(torch.abs(predicted.flatten() - actual.flatten()))\n",
    "\n",
    "def loss_mse(predicted, actual):\n",
    "    return torch.mean((predicted.flatten() - actual.flatten())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedPowerSpectrum(torch.nn.Module):\n",
    "    def __init__(self, combiner):\n",
    "        super().__init__()\n",
    "\n",
    "        self.combiner = combiner\n",
    "        self.power_spectrum = PowerSpectrum()\n",
    "\n",
    "    def forward(self, spherical_expansion):\n",
    "        combined = self.combiner(spherical_expansion)\n",
    "\n",
    "        return self.power_spectrum(combined)\n",
    "\n",
    "        \n",
    "class MultiBodyOrderModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        composition, \n",
    "        power_spectrum,\n",
    "        composition_regularizer,\n",
    "        radial_spectrum_regularizer,\n",
    "        power_spectrum_regularizer,        \n",
    "        optimizable_weights,\n",
    "        random_initial_weights,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sum_structure = SumStructures()\n",
    "\n",
    "        # optimizable_weights = False is not very well tested ...\n",
    "        assert optimizable_weights\n",
    "\n",
    "        self.composition = composition\n",
    "        \n",
    "        if composition_regularizer is None:\n",
    "            self.composition_model = None\n",
    "        else:\n",
    "            self.composition_model=LinearModel(\n",
    "            regularizer=composition_regularizer,\n",
    "            optimizable_weights=optimizable_weights,\n",
    "            random_initial_weights=random_initial_weights,\n",
    "        )\n",
    "        self.power_spectrum = power_spectrum\n",
    "        if radial_spectrum_regularizer is None:\n",
    "            self.radial_spectrum_model = None\n",
    "        else:\n",
    "            self.radial_spectrum_model = LinearModel(\n",
    "                regularizer=radial_spectrum_regularizer,\n",
    "                optimizable_weights=optimizable_weights,\n",
    "                random_initial_weights=random_initial_weights,\n",
    "            )\n",
    "\n",
    "        self.power_spectrum_model = LinearModel(\n",
    "            regularizer=power_spectrum_regularizer,\n",
    "            optimizable_weights=optimizable_weights,\n",
    "            random_initial_weights=random_initial_weights,\n",
    "        )\n",
    "\n",
    "        self.combiner = combiner, \n",
    "        self.optimizable_weights = optimizable_weights\n",
    "        self.random_initial_weights = random_initial_weights\n",
    "\n",
    "    def forward(self, frames, radial_spectrum, spherical_expansion, forward_forces=False):\n",
    "        if not forward_forces:\n",
    "            # remove gradients if we don't need them\n",
    "            spherical_expansion = remove_gradient(spherical_expansion)\n",
    "            if radial_spectrum is not None:\n",
    "                radial_spectrum = remove_gradient(radial_spectrum)                \n",
    "        \n",
    "        power_spectrum = self.power_spectrum(spherical_expansion)\n",
    "        power_spectrum_per_structure = self.sum_structure(power_spectrum)\n",
    "\n",
    "        radial_spectrum_per_structure = self.sum_structure(radial_spectrum)\n",
    "\n",
    "        energies, forces = self.power_spectrum_model(power_spectrum_per_structure, with_forces=forward_forces)\n",
    "        \n",
    "        if self.radial_spectrum_model is not None:\n",
    "            energies_rs, forces_rs = self.radial_spectrum_model(radial_spectrum_per_structure, with_forces=forward_forces)\n",
    "            # NBNBNB - these should be +=, I'm switching off the power spectrum to reduce overfitting\n",
    "            energies += energies_rs  \n",
    "            if forces_rs is not None:\n",
    "                forces += forces_rs\n",
    "                \n",
    "        if self.composition_model is not None:\n",
    "            energies_cmp, _ = self.composition_model(self.composition(frames))\n",
    "            energies += energies_cmp\n",
    "            forces = None\n",
    "    \n",
    "        return energies, forces\n",
    "\n",
    "    def initialize_model_weights(self, frames, radial_spectrum, spherical_expansion, energies, forces=None):\n",
    "        if forces is None:\n",
    "            # remove gradients if we don't need them\n",
    "            spherical_expansion = remove_gradient(spherical_expansion)\n",
    "            if radial_spectrum is not None:\n",
    "                radial_spectrum = remove_gradient(radial_spectrum)\n",
    "            \n",
    "        power_spectrum = self.power_spectrum(spherical_expansion)\n",
    "        power_spectrum_per_structure = self.sum_structure(power_spectrum)\n",
    "\n",
    "        radial_spectrum_per_structure = self.sum_structure(radial_spectrum)\n",
    "        \n",
    "        self.power_spectrum_model.initialize_model_weights(power_spectrum_per_structure, energies, forces)\n",
    "\n",
    "        if self.radial_spectrum_model is not None:\n",
    "            self.radial_spectrum_model.initialize_model_weights(radial_spectrum_per_structure, energies, forces)\n",
    "        \n",
    "        if self.composition_model is not None:\n",
    "            self.composition_model.initialize_model_weights(self.composition(frames), energies)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species combination only\n",
    "N_PSEUDO_SPECIES = 2\n",
    "combiner = CombineSpecies(species=all_species, n_pseudo_species=N_PSEUDO_SPECIES)\n",
    "\n",
    "# # species combination and then radial basis combination\n",
    "# N_COMBINED_RADIAL = 4\n",
    "# combiner = torch.nn.Sequential(\n",
    "#     CombineSpecies(species=all_species, n_pseudo_species=N_PSEUDO_SPECIES),\n",
    "#     CombineRadial(max_radial=HYPERS_SMALL[\"max_radial\"], n_combined_radial=N_COMBINED_RADIAL),\n",
    "# )\n",
    "\n",
    "# # combine both radial and species information at the same time\n",
    "# combiner = CombineRadialSpecies(\n",
    "#     n_species=len(all_species), \n",
    "#     max_radial=HYPERS_SMALL[\"max_radial\"], \n",
    "#     n_combined_basis=N_COMBINED_RADIAL*N_PSEUDO_SPECIES,\n",
    "# )\n",
    "\n",
    "composition=CompositionFeatures(all_species)\n",
    "power_spectrum = CombinedPowerSpectrum(combiner)\n",
    "\n",
    "LINALG_REGULARIZER_ENERGIES = 1e-2\n",
    "LINALG_REGULARIZER_FORCES = 1e-1\n",
    "\n",
    "model = MultiBodyOrderModel(\n",
    "    composition = composition,\n",
    "    power_spectrum=power_spectrum, \n",
    "    composition_regularizer=[1e-10],\n",
    "    radial_spectrum_regularizer=[LINALG_REGULARIZER_ENERGIES, LINALG_REGULARIZER_FORCES],\n",
    "    power_spectrum_regularizer=[LINALG_REGULARIZER_ENERGIES, LINALG_REGULARIZER_FORCES],\n",
    "    optimizable_weights=True, \n",
    "    random_initial_weights=True,\n",
    ")\n",
    "\n",
    "if model.optimizable_weights:\n",
    "    TORCH_REGULARIZER_COMPOSITION = 1e-4\n",
    "    TORCH_REGULARIZER_RADIAL_SPECTRUM = 5e0\n",
    "    TORCH_REGULARIZER_POWER_SPECTRUM = 2e1\n",
    "else:\n",
    "    TORCH_REGULARIZER_RADIAL_SPECTRUM = 0.0\n",
    "    TORCH_REGULARIZER_POWER_SPECTRUM = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device, dtype=torch.get_default_dtype())\n",
    "\n",
    "if model.random_initial_weights:\n",
    "    dataloader_initialization = train_dataloader_single_frame\n",
    "else:\n",
    "    dataloader_initialization = train_dataloader_no_batch\n",
    "\n",
    "# initialize the model\n",
    "with torch.no_grad():\n",
    "    for frames, radial_spectrum, spherical_expansions, energies, _ in dataloader_initialization:\n",
    "        # we want to intially train the model on all frames, to ensure the\n",
    "        # support points come from the full dataset.\n",
    "        model.initialize_model_weights(frames, radial_spectrum, spherical_expansions, energies)\n",
    "        break\n",
    "\n",
    "del radial_spectrum, spherical_expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=lr, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "filename = f\"{model.__class__.__name__}-{N_PSEUDO_SPECIES}-mixed-{n_train}-train\"\n",
    "if model.optimizable_weights:\n",
    "    filename += \"-opt-weights\"\n",
    "\n",
    "if model.random_initial_weights:\n",
    "    filename += \"-random-weights\"\n",
    "\n",
    "output = open(f\"{filename}.dat\", \"w\")\n",
    "output.write(\"# epoch  train_loss  test_mae\\n\")\n",
    "n_epochs_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.optimizable_weights\n",
    "\n",
    "for epoch in range(25):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    def single_step():\n",
    "        optimizer.zero_grad()        \n",
    "        for frame, radial_spectrum, spherical_expansions, energies, _ in train_dataloader:            \n",
    "            predicted, _ = model(frame, radial_spectrum, spherical_expansions, forward_forces=False)\n",
    "\n",
    "            loss = loss_mse(predicted, energies)\n",
    "            # regularization\n",
    "            # TODO: how does this interact with backward prop??\n",
    "            loss += TORCH_REGULARIZER_COMPOSITION * torch.linalg.norm(model.composition_model.weights)\n",
    "            loss += TORCH_REGULARIZER_RADIAL_SPECTRUM * torch.linalg.norm(model.radial_spectrum_model.weights)\n",
    "            loss += TORCH_REGULARIZER_POWER_SPECTRUM * torch.linalg.norm(model.power_spectrum_model.weights)\n",
    "\n",
    "            loss.backward(retain_graph=False)\n",
    "\n",
    "        return loss\n",
    "            \n",
    "    loss = optimizer.step(single_step)\n",
    "    loss = loss.item()\n",
    "    all_losses.append(loss)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"norms\", np.linalg.norm(model.composition_model.weights.detach()),\n",
    "                  np.linalg.norm(model.radial_spectrum_model.weights.detach()),\n",
    "                  np.linalg.norm(model.power_spectrum_model.weights.detach())\n",
    "                 )\n",
    "        print(\"gradients\", \n",
    "                  np.linalg.norm(model.composition_model.weights.grad),\n",
    "                  np.linalg.norm(model.radial_spectrum_model.weights.grad),\n",
    "                  np.linalg.norm(model.power_spectrum_model.weights.grad)\n",
    "                 )\n",
    "        with torch.no_grad():\n",
    "            predicted = []\n",
    "            reference = []\n",
    "            for frame, radial_spectrum, spherical_expansions, energies, _ in test_dataloader:\n",
    "                reference.append(energies)\n",
    "                predicted_e, _ = model(frame, radial_spectrum, spherical_expansions, forward_forces=False)\n",
    "                predicted.append(predicted_e)\n",
    "\n",
    "            reference = torch.vstack(reference)\n",
    "            predicted = torch.vstack(predicted)\n",
    "            mae = loss_mae(predicted, reference)\n",
    "\n",
    "            output.write(f\"{n_epochs_total} {loss} {mae}\\n\")\n",
    "            output.flush()\n",
    "\n",
    "        print(f\"epoch {n_epochs_total} took {epoch_time:.4}s, optimizer loss={loss:.4}, test mae={mae:.4}\")\n",
    "    \n",
    "    del spherical_expansions, loss, mae\n",
    "        \n",
    "    n_epochs_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.composition_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted, reference, 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tpredicted = []\n",
    "    treference = []\n",
    "    for frame, radial_spectrum, spherical_expansions, energies, _ in train_dataloader:\n",
    "        treference.append(energies)\n",
    "        predicted_e, _ = model(frame, radial_spectrum, spherical_expansions, forward_forces=False)\n",
    "        tpredicted.append(predicted_e)\n",
    "\n",
    "    treference = torch.vstack(treference)\n",
    "    tpredicted = torch.vstack(tpredicted)\n",
    "    mae = loss_mae(tpredicted, treference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tpredicted, treference, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting forces with forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_forces(model, dataloader):\n",
    "    predicted_e = []\n",
    "    reference_e = []\n",
    "    predicted_f = []\n",
    "    reference_f = []\n",
    "    for frame, radial_spectrum, spherical_expansions, energies, forces in dataloader:\n",
    "        reference_e.append(energies)\n",
    "        reference_f.append(forces)\n",
    "        e, f = model(frame, radial_spectrum, spherical_expansions, forward_forces=True)\n",
    "        predicted_e.append(e)\n",
    "        predicted_f.append(f)\n",
    "\n",
    "    reference_e = torch.vstack(reference_e)\n",
    "    predicted_e = torch.vstack(predicted_e)\n",
    "\n",
    "    reference_f = torch.vstack(reference_f)\n",
    "    predicted_f = torch.vstack(predicted_f)\n",
    "\n",
    "    return reference_e, predicted_e, reference_f, predicted_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_plots(reference_e, predicted_e, reference_f, predicted_f):\n",
    "    predicted_e = predicted_e.detach()\n",
    "    predicted_f = predicted_f.detach()\n",
    "\n",
    "    fig, (ax_e, ax_f) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    mae = loss_mae(predicted_e, reference_e)\n",
    "    rmse = loss_rmse(predicted_e, reference_e)\n",
    "    ax_e.scatter(reference_e.cpu(), predicted_e.cpu())\n",
    "    x = (torch.min(reference_e.flatten()).item(), torch.max(reference_e.flatten()).item())\n",
    "    ax_e.plot(x, x, color=\"red\")\n",
    "    ax_e.set_title(f\"energies, MAE={mae:.4}, RMSE={rmse:.4}\")\n",
    "    ax_e.set_xlabel(\"actual\")\n",
    "    ax_e.set_ylabel(\"predicted\")\n",
    "\n",
    "    mae = loss_mae(predicted_f, reference_f)\n",
    "    rmse = loss_rmse(predicted_f, reference_f)\n",
    "    ax_f.scatter(reference_f.cpu(), predicted_f.cpu())\n",
    "    x = (torch.min(reference_f.flatten()).item(), torch.max(reference_f.flatten()).item())\n",
    "    ax_f.plot(x, x, color=\"red\")\n",
    "    ax_f.set_title(f\"forces, MAE={mae:.4}, RMSE={rmse:.4}\")\n",
    "    ax_f.set_xlabel(\"actual\")\n",
    "    ax_f.set_ylabel(\"predicted\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = parity_plots(*evaluate_model_with_forces(model, test_dataloader_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_finite_differences(model, frame, delta=1e-6):\n",
    "    frame = frame.copy()\n",
    "    delta_frame = frame.copy()\n",
    "    delta_frame.positions[3, 1] += delta\n",
    "\n",
    "    dataset = AtomisticDataset(\n",
    "        [frame, delta_frame], \n",
    "        all_species, \n",
    "        HYPERS_GRAD, \n",
    "        torch.zeros(2, 1), \n",
    "        radial_spectrum_n_max=12,\n",
    "    )\n",
    "    dataloader = create_dataloader(\n",
    "        dataset,\n",
    "        batch_size=len(dataset),\n",
    "        shuffle=False,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    for frame, radial_spectrum, spherical_expansions, _, _ in dataloader:\n",
    "        predicted_e, predicted_f = model(frame, radial_spectrum, spherical_expansions, forward_forces=True)\n",
    "\n",
    "    finite_diff = - (predicted_e[1] - predicted_e[0]) / delta\n",
    "    print(\"finite difference =\", finite_diff.item())\n",
    "    print(\"computed gradient =\", predicted_f[3, 1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.get_default_dtype() == torch.float64:\n",
    "    delta = 1e-6\n",
    "else:\n",
    "    delta = 1e-3\n",
    "\n",
    "check_finite_differences(model, train_frames[22], delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fdb860dc9f423b713ecf03ec3bee4ef4df65400e892ebee65bf9175396f229c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
