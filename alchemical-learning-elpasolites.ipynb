{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ase.io\n",
    "\n",
    "from utils.soap import compute_spherical_expansion_librascal, PowerSpectrum\n",
    "from utils.gap import train_gap_model\n",
    "from utils.alchemical import AlchemicalCombine\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read(\"data/elpasolites_10590.xyz\", \":600\")\n",
    "energies = torch.tensor(np.loadtxt(\"data/elpasolites_10590_evpa.dat\")[:600])\n",
    "\n",
    "train_frames = frames[:500]\n",
    "test_frames = frames[500:]\n",
    "\n",
    "train_energies = energies[:500]\n",
    "test_energies = energies[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_species = set()\n",
    "for frame in frames:\n",
    "    global_species.update(frame.numbers)\n",
    "\n",
    "global_species = list(map(lambda u: int(u), global_species))\n",
    "\n",
    "HYPERS = {\n",
    "    \"interaction_cutoff\": 5.0,\n",
    "    \"max_angular\": 4,\n",
    "    \"max_radial\": 4,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "    \"compute_gradients\": False,\n",
    "    \"expansion_by_species_method\": \"user defined\",\n",
    "    \"global_species\": global_species,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spherical_expansions, train_slices = compute_spherical_expansion_librascal(train_frames, HYPERS)\n",
    "test_spherical_expansions, test_slices = compute_spherical_expansion_librascal(test_frames, HYPERS)\n",
    "\n",
    "train_species = torch.hstack([torch.tensor(frame.numbers) for frame in train_frames])\n",
    "test_species = torch.hstack([torch.tensor(frame.numbers) for frame in test_frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: standard GAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGap(torch.nn.Module):\n",
    "    def __init__(self, n_support, zeta, lambdas):\n",
    "        super().__init__()\n",
    "        self.power_spectrum = PowerSpectrum()\n",
    "\n",
    "        self.n_support = n_support\n",
    "        self.zeta = zeta\n",
    "        self.lambdas = lambdas\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, spherical_expansion, all_species, structures_slices, energies):\n",
    "        power_spectrum = self.power_spectrum(spherical_expansion)\n",
    "\n",
    "        self.model = train_gap_model(\n",
    "            power_spectrum, \n",
    "            all_species,\n",
    "            structures_slices,\n",
    "            energies, \n",
    "            self.n_support, \n",
    "            zeta=self.zeta, \n",
    "            lambdas=self.lambdas\n",
    "        )\n",
    "\n",
    "    def forward(self, spherical_expansion, all_species, structures_slices):\n",
    "        ps = self.power_spectrum(spherical_expansion)\n",
    "        return self.model(ps, all_species, structures_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_support = {\n",
    "    species: 10 for species in global_species\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseGap(n_support, zeta=2, lambdas=[1e-6, 1e-6])\n",
    "base_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energies_training_set = base_model(\n",
    "    train_spherical_expansions, train_species, train_slices\n",
    ")\n",
    "\n",
    "predicted_energies_test_set = base_model(\n",
    "    test_spherical_expansions, test_species, test_slices\n",
    ")\n",
    "\n",
    "train_loss = loss_fn(predicted_energies_training_set.squeeze(), train_energies)\n",
    "test_loss = loss_fn(predicted_energies_test_set.squeeze(), test_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].scatter(train_energies, predicted_energies_training_set.numpy())\n",
    "x = np.linspace(train_energies.min(), train_energies.max(), 20)\n",
    "ax[0].plot(x, x, color='r')\n",
    "\n",
    "ax[0].set_title(f'Training set — loss = {train_loss:.4}')\n",
    "ax[0].set_xlabel('DFT')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "ax[1].scatter(predicted_energies_test_set.numpy(), test_energies)\n",
    "x = np.linspace(test_energies.min(), test_energies.max(), 20)\n",
    "ax[1].plot(x, x, color='r')\n",
    "\n",
    "ax[1].set_title(f'Test set — loss = {test_loss:.4}')\n",
    "ax[1].set_xlabel('DFT')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "\n",
    "fig.suptitle(f\"Base model — {sum(v for v in n_support.values())} GAP support point\")\n",
    "fig.savefig(\"base-model.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedSpeciesGap(torch.nn.Module):\n",
    "    def __init__(self, species, n_pseudo_species, n_support, zeta, lambdas, optimizable_weights):\n",
    "        super().__init__()\n",
    "        self.power_spectrum = PowerSpectrum()\n",
    "        self.alchemical = AlchemicalCombine(species, n_pseudo_species)\n",
    "\n",
    "        self.n_support = n_support\n",
    "        self.zeta = zeta\n",
    "        self.lambdas = lambdas\n",
    "\n",
    "        self.optimizable_weights = optimizable_weights\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, spherical_expansion, all_species, structures_slices, energies):\n",
    "        combined = self.alchemical(spherical_expansion)\n",
    "        power_spectrum = self.power_spectrum(combined)\n",
    "        \n",
    "        self.model = train_gap_model(\n",
    "            power_spectrum, \n",
    "            all_species,\n",
    "            structures_slices,\n",
    "            energies, \n",
    "            self.n_support, \n",
    "            zeta=self.zeta, \n",
    "            lambdas=self.lambdas,\n",
    "            optimizable_weights=self.optimizable_weights,\n",
    "        )\n",
    "\n",
    "    def forward(self, spherical_expansion, all_species, structures_slices):\n",
    "        combined = self.alchemical(spherical_expansion)\n",
    "        ps = self.power_spectrum(combined)\n",
    "        return self.model(ps, all_species, structures_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PSEUDO_SPECIES = 2\n",
    "\n",
    "mixed_species_model = MixedSpeciesGap(\n",
    "    global_species, \n",
    "    n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "    n_support=n_support, \n",
    "    zeta=2, \n",
    "    lambdas=[1e-6, 1e-6],\n",
    "    optimizable_weights=False,\n",
    ")\n",
    "mixed_species_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energies_training_set = mixed_species_model(\n",
    "    train_spherical_expansions, train_species, train_slices\n",
    ").detach()\n",
    "\n",
    "predicted_energies_test_set = mixed_species_model(\n",
    "    test_spherical_expansions, test_species, test_slices\n",
    ").detach()\n",
    "\n",
    "train_loss = loss_fn(predicted_energies_training_set.squeeze(), train_energies)\n",
    "test_loss = loss_fn(predicted_energies_test_set.squeeze(), test_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].scatter(train_energies, predicted_energies_training_set.numpy())\n",
    "x = np.linspace(train_energies.min(), train_energies.max(), 20)\n",
    "ax[0].plot(x, x, color='r')\n",
    "\n",
    "ax[0].set_title(f'Training set — loss = {train_loss:.4}')\n",
    "ax[0].set_xlabel('DFT')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "ax[1].scatter(predicted_energies_test_set.numpy(), test_energies)\n",
    "x = np.linspace(test_energies.min(), test_energies.max(), 20)\n",
    "ax[1].plot(x, x, color='r')\n",
    "\n",
    "ax[1].set_title(f'Test set — loss = {test_loss:.4}')\n",
    "ax[1].set_xlabel('DFT')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "\n",
    "fig.suptitle(f\"Combined species, before species optimization — {sum(v for v in n_support.values())} GAP support point — {N_PSEUDO_SPECIES} pseudo species\")\n",
    "fig.savefig(\"species-before.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_combining_matrix = mixed_species_model.alchemical.combining_matrix.detach().numpy()\n",
    "\n",
    "plt.scatter(species_combining_matrix[:, 0], species_combining_matrix[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop for the species projection only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_species_model = MixedSpeciesGap(\n",
    "    global_species, \n",
    "    n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "    n_support=n_support, \n",
    "    zeta=2, \n",
    "    lambdas=[1e-6, 1e-6],\n",
    "    optimizable_weights=False,\n",
    ")\n",
    "mixed_species_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# there should only be 1 parameter, the species coupling\n",
    "assert len(list(mixed_species_model.parameters())) == 1\n",
    "optimizer = torch.optim.AdamW(mixed_species_model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(0):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    mixed_species_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "    predicted = mixed_species_model(\n",
    "        train_spherical_expansions, train_species, train_slices\n",
    "    )    \n",
    "\n",
    "    loss = loss_fn(predicted.squeeze(), train_energies)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energies_training_set = mixed_species_model(\n",
    "    train_spherical_expansions, train_species, train_slices\n",
    ").detach()\n",
    "\n",
    "predicted_energies_test_set = mixed_species_model(\n",
    "    test_spherical_expansions, test_species, test_slices\n",
    ").detach()\n",
    "\n",
    "train_loss = loss_fn(predicted_energies_training_set.squeeze(), train_energies)\n",
    "test_loss = loss_fn(predicted_energies_test_set.squeeze(), test_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].scatter(train_energies, predicted_energies_training_set.numpy())\n",
    "x = np.linspace(train_energies.min(), train_energies.max(), 20)\n",
    "ax[0].plot(x, x, color='r')\n",
    "\n",
    "ax[0].set_title(f'Training set — loss = {train_loss:.4}')\n",
    "ax[0].set_xlabel('DFT')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "ax[1].scatter(predicted_energies_test_set.numpy(), test_energies)\n",
    "x = np.linspace(test_energies.min(), test_energies.max(), 20)\n",
    "ax[1].plot(x, x, color='r')\n",
    "\n",
    "ax[1].set_title(f'Test set — loss = {test_loss:.4}')\n",
    "ax[1].set_xlabel('DFT')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "\n",
    "fig.suptitle(f\"Combined species, after species optimization — {sum(v for v in n_support.values())} GAP support point — {N_PSEUDO_SPECIES} pseudo species\")\n",
    "fig.savefig(\"species-after.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_combining_matrix = mixed_species_model.alchemical.combining_matrix.detach().numpy()\n",
    "\n",
    "plt.scatter(species_combining_matrix[:, 0], species_combining_matrix[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop for both species and kernel weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_species_model = MixedSpeciesGap(\n",
    "    global_species, \n",
    "    n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "    n_support=n_support, \n",
    "    zeta=2, \n",
    "    lambdas=[1e-6, 1e-6],\n",
    "    optimizable_weights=True,\n",
    ")\n",
    "mixed_species_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# there should only be n_species + 1 parameters\n",
    "assert len(list(mixed_species_model.parameters())) == len(global_species) + 1\n",
    "\n",
    "optimizer = torch.optim.AdamW(mixed_species_model.parameters(), lr=0.1)\n",
    "# optimizer = torch.optim.LBFGS(mixed_species_model.parameters(), lr=1)\n",
    "\n",
    "regularizer = 1e-1\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "    def single_step():\n",
    "        optimizer.zero_grad()\n",
    "        predicted = mixed_species_model(\n",
    "            train_spherical_expansions, train_species, train_slices\n",
    "        )    \n",
    "\n",
    "        loss = loss_fn(predicted.squeeze(), train_energies)\n",
    "        # regularize the loss\n",
    "        for weights in mixed_species_model.model.weights.values():\n",
    "            loss += regularizer * torch.linalg.norm(weights)\n",
    "        \n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    loss = optimizer.step(single_step)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energies_training_set = mixed_species_model(\n",
    "    train_spherical_expansions, train_species, train_slices\n",
    ").detach()\n",
    "\n",
    "predicted_energies_test_set = mixed_species_model(\n",
    "    test_spherical_expansions, test_species, test_slices\n",
    ").detach()\n",
    "\n",
    "train_loss = loss_fn(predicted_energies_training_set.squeeze(), train_energies)\n",
    "test_loss = loss_fn(predicted_energies_test_set.squeeze(), test_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].scatter(train_energies, predicted_energies_training_set.numpy())\n",
    "x = np.linspace(train_energies.min(), train_energies.max(), 20)\n",
    "ax[0].plot(x, x, color='r')\n",
    "\n",
    "ax[0].set_title(f'Training set — loss = {train_loss:.4}')\n",
    "ax[0].set_xlabel('DFT')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "ax[1].scatter(predicted_energies_test_set.numpy(), test_energies)\n",
    "x = np.linspace(test_energies.min(), test_energies.max(), 20)\n",
    "ax[1].plot(x, x, color='r')\n",
    "\n",
    "ax[1].set_title(f'Test set — loss = {test_loss:.4}')\n",
    "ax[1].set_xlabel('DFT')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "\n",
    "fig.suptitle(f\"Combined species + GAP, after optimization — {sum(v for v in n_support.values())} GAP support point — {N_PSEUDO_SPECIES} pseudo species\")\n",
    "fig.savefig(\"species-gap-opt.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_combining_matrix = mixed_species_model.alchemical.combining_matrix.detach().numpy()\n",
    "\n",
    "plt.scatter(species_combining_matrix[:, 0], species_combining_matrix[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ef12eb5922cf8d604aeb1dfa412e3da3665f54b5e701463f21d300328cee18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
