{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "#import torchviz\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ase.io\n",
    "\n",
    "from utils.soap import compute_spherical_expansion_librascal\n",
    "\n",
    "from utils.models import FullGapModel, SparseGapModel, PerSpeciesSparseGapModel, LinearModel\n",
    "from utils.models import MixedSpeciesFullGapModel, MixedSpeciesSparseGapModel, MixedSpeciesLinearModel\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 80 training frames\n"
     ]
    }
   ],
   "source": [
    "n_frames = 100\n",
    "\n",
    "frames = ase.io.read(\"data/elpasolites_10590.xyz\", f\":{n_frames}\")\n",
    "#methane_frames = ase.io.read(\"data/methane-100.xyz\", f\":{n_frames}\")\n",
    "energies = torch.tensor(np.loadtxt(\"data/elpasolites_10590_evpa.dat\")[:n_frames])\n",
    "\n",
    "n_train = int(0.8 * len(frames))\n",
    "\n",
    "train_frames = frames[:n_train]\n",
    "test_frames = frames[n_train:]\n",
    "\n",
    "train_energies = energies[:n_train]\n",
    "test_energies = energies[n_train:]\n",
    "\n",
    "print(f\"using {n_train} training frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_species = set()\n",
    "for frame in frames:\n",
    "    global_species.update(frame.numbers)\n",
    "\n",
    "global_species = list(map(lambda u: int(u), global_species))\n",
    "\n",
    "HYPERS_SMALL = {\n",
    "    \"interaction_cutoff\": 5.0,\n",
    "    \"max_angular\": 2,\n",
    "    \"max_radial\": 2,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "    \"compute_gradients\": False,\n",
    "    \"expansion_by_species_method\": \"user defined\",\n",
    "    \"global_species\": global_species,\n",
    "}\n",
    "\n",
    "HYPERS_MJW = {\n",
    "    \"interaction_cutoff\": 5.0,\n",
    "    \"max_angular\": 3,\n",
    "    \"max_radial\": 4,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "    \"compute_gradients\": False,\n",
    "    \"expansion_by_species_method\": \"user defined\",\n",
    "    \"global_species\": global_species,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils.gap\n",
    "\n",
    "# def structure_sum(kernel):\n",
    "#     return utils.gap.common.SumStructureKernel.apply(kernel, test_slices, train_slices)\n",
    "\n",
    "# rand_kernel = torch.rand((len(test_slices), len(train_slices)), requires_grad=True)\n",
    "# torch.autograd.gradcheck(structure_sum, rand_kernel, fast_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: GAP model without species combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_model(model, name, file):\n",
    "    predicted_energies_training_set = model(\n",
    "        train_spherical_expansions, train_species, train_slices\n",
    "    )\n",
    "\n",
    "    predicted_energies_test_set = model(\n",
    "        test_spherical_expansions, test_species, test_slices\n",
    "    )\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    train_loss = loss_fn(predicted_energies_training_set.squeeze(), train_energies)\n",
    "    test_loss = loss_fn(predicted_energies_test_set.squeeze(), test_energies)\n",
    "\n",
    "    train_loss *= 100 / train_energies.std()\n",
    "    test_loss *= 100 / test_energies.std()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    ax[0].scatter(train_energies, predicted_energies_training_set.detach().numpy())\n",
    "    x = np.linspace(train_energies.min(), train_energies.max(), 20)\n",
    "    ax[0].plot(x, x, color='r')\n",
    "\n",
    "    ax[0].set_title(f'Training set — loss = {train_loss:.3} %RMSE')\n",
    "    ax[0].set_xlabel('DFT')\n",
    "    ax[0].set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "    ax[1].scatter(test_energies, predicted_energies_test_set.detach().numpy())\n",
    "    x = np.linspace(test_energies.min(), test_energies.max(), 20)\n",
    "    ax[1].plot(x, x, color='r')\n",
    "\n",
    "    ax[1].set_title(f'Test set — loss = {test_loss:.3} %RMSE')\n",
    "    ax[1].set_xlabel('DFT')\n",
    "    ax[1].set_ylabel('Predicted')\n",
    "\n",
    "    fig.suptitle(name)\n",
    "    fig.savefig(file, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_spherical_expansions, train_slices = compute_spherical_expansion_librascal(train_frames, HYPERS_SMALL)\n",
    "# test_spherical_expansions, test_slices = compute_spherical_expansion_librascal(test_frames, HYPERS_SMALL)\n",
    "\n",
    "# train_species = torch.hstack([torch.tensor(frame.numbers) for frame in train_frames])\n",
    "# test_species = torch.hstack([torch.tensor(frame.numbers) for frame in test_frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = LinearModel(lambdas=[1e-6])\n",
    "# linear.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# evaluate_and_plot_model(\n",
    "#     linear, \n",
    "#     f\"Linear model\",\n",
    "#     \"linear.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_gap = FullGapModel(zeta=2, lambdas=[1e-1])\n",
    "# full_gap.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# evaluate_and_plot_model(\n",
    "#     full_gap, \n",
    "#     f\"Full GAP model\",\n",
    "#     \"full-gap.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_support = 100\n",
    "\n",
    "# sparse_gap = SparseGapModel(n_support=n_support, zeta=2, lambdas=[1e-1])\n",
    "# sparse_gap.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# evaluate_and_plot_model(\n",
    "#     sparse_gap, \n",
    "#     f\"Sparse GAP model — {n_support} GAP support point\",\n",
    "#     \"sparse-gap.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse GAP, one model per central atom species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_support = {\n",
    "#     species: 5 for species in global_species\n",
    "# }\n",
    "\n",
    "# per_species_sparse_model = PerSpeciesSparseGapModel(\n",
    "#     n_support, \n",
    "#     zeta=2, \n",
    "#     lambdas=[1e-3], \n",
    "#     jitter=1e-10\n",
    "# )\n",
    "# per_species_sparse_model.fit(train_spherical_expansions, train_species, train_slices, train_energies)\n",
    "\n",
    "# evaluate_and_plot_model(\n",
    "#     per_species_sparse_model, \n",
    "#     f\"Sparse model per species — {sum(n_support.values())} GAP support point\",\n",
    "#     \"basic-sparse-per-species.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # plot computational graph on a smaller dataset\n",
    "# small_hypers = copy.deepcopy(HYPERS_SMALL)\n",
    "# small_hypers[\"max_angular\"] = 1\n",
    "# small_hypers[\"max_radial\"] = 1\n",
    "# small_hypers[\"global_species\"] = [6, 1]\n",
    "\n",
    "\n",
    "# for i in methane_frames:\n",
    "#     i.cell = np.array([50,50,50])\n",
    "#     i.center(axis = (0,1,2), about  = (25, 25, 25))\n",
    "# small_train_frames = methane_frames[2:4]\n",
    "# small_test_frames = methane_frames[:2]\n",
    "\n",
    "\n",
    "# small_train_energies = torch.tensor([f.info[\"energy\"] for f in small_train_frames])\n",
    "\n",
    "# small_train_spherical_expansions, small_train_slices = compute_spherical_expansion_librascal(\n",
    "#     small_train_frames, small_hypers\n",
    "# )\n",
    "# small_train_species = torch.hstack([torch.tensor(frame.numbers) for frame in small_train_frames])\n",
    "\n",
    "# small_test_spherical_expansions, small_test_slices = compute_spherical_expansion_librascal(\n",
    "#     small_test_frames, small_hypers\n",
    "# )\n",
    "# small_test_species = torch.hstack([torch.tensor(frame.numbers) for frame in small_test_frames])\n",
    "\n",
    "# small_n_support = {1: 10, 6: 10}\n",
    "\n",
    "# small_model = MixedSpeciesLinearModel(\n",
    "#     global_species, \n",
    "#     n_pseudo_species=2, \n",
    "#     lambdas=[1e-3, 1e-6],\n",
    "#     optimizable_weights=True,\n",
    "# )\n",
    "# small_model.fit(\n",
    "#     small_train_spherical_expansions, \n",
    "#     small_train_species, \n",
    "#     small_train_slices, \n",
    "#     small_train_energies\n",
    "# )\n",
    "\n",
    "# torchviz_params = {}\n",
    "# for l, sph in small_test_spherical_expansions.items():\n",
    "#     sph.requires_grad_(True)\n",
    "#     torchviz_params[f\"sph l={l}\"] = sph\n",
    "\n",
    "# #for s, w in small_model.model.weights.items():\n",
    "# #    w.requires_grad_(True)\n",
    "# #    torchviz_params[f\"weight species={s}\"] = w\n",
    "# torchviz_params[f\"weight species=1\"] = small_model.model.weights\n",
    "\n",
    "# result = small_model(small_test_spherical_expansions, small_test_species, small_test_slices)\n",
    "\n",
    "# torchviz.make_dot(result, params=torchviz_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in small_model.model.weights:\n",
    "#     print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomisticDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, frames, hypers, energies):\n",
    "        self.spherical_expansions = []\n",
    "        for frame in frames:\n",
    "            se, slices = compute_spherical_expansion_librascal([frame], hypers)\n",
    "            self.spherical_expansions.append(se)\n",
    "        \n",
    "        self.species = [torch.tensor(frame.numbers) for frame in frames]\n",
    "        self.energies = energies\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spherical_expansions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.spherical_expansions[idx], self.species[idx], self.energies[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_data_cpu(data):\n",
    "    spherical_expansion = {\n",
    "        lambda_: torch.vstack([d[0][lambda_] for d in data])\n",
    "        for lambda_ in data[0][0].keys()\n",
    "    }\n",
    "\n",
    "    species = torch.hstack([d[1] for d in data])\n",
    "    energies = torch.vstack([d[2] for d in data])\n",
    "\n",
    "    slices = []\n",
    "    start = 0\n",
    "    for d in data:\n",
    "        stop = start + d[1].shape[0]\n",
    "        slices.append(slice(start, stop))\n",
    "        start = stop\n",
    "\n",
    "    return spherical_expansion, species, slices, energies\n",
    "\n",
    "def collate_data_gpu(data):\n",
    "    spherical_expansion, species, slices, energies = collate_data_cpu(data)\n",
    "\n",
    "    spherical_expansion = {\n",
    "        lambda_: se.to(device='cuda') for lambda_, se in spherical_expansion.items()\n",
    "    }\n",
    "\n",
    "    return spherical_expansion, species.to(device='cuda'), slices, energies.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AtomisticDataset(train_frames, HYPERS_MJW, train_energies)\n",
    "test_dataset = AtomisticDataset(test_frames, HYPERS_MJW, test_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PSEUDO_SPECIES = 4\n",
    "UPDATE_SUPPORT_POINTS = False\n",
    "\n",
    "# Full kernel, optimize everything with gradients\n",
    "mixed_species_model = MixedSpeciesFullGapModel(\n",
    "    global_species, \n",
    "    n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "    zeta=1, \n",
    "    lambdas=[1e-3],\n",
    "    optimizable_weights=True,\n",
    "    random_initial_weights=True,\n",
    "    detach_support_points=True,\n",
    ")\n",
    "\n",
    "# # Full kernel, optimize species with gradients, weights with linear algebra\n",
    "# mixed_species_model = MixedSpeciesFullGapModel(\n",
    "#     global_species, \n",
    "#     n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "#     zeta=1, \n",
    "#     lambdas=[1e-1, 1e-6],\n",
    "#     optimizable_weights=False,\n",
    "# )\n",
    "\n",
    "# # Sparse kernel, optimize everything with gradients\n",
    "# mixed_species_model = MixedSpeciesSparseGapModel(\n",
    "#     global_species, \n",
    "#     n_support=100,\n",
    "#     n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "#     zeta=1, \n",
    "#     lambdas=[1e-3, 1e-6],\n",
    "#     optimizable_weights=True,\n",
    "# )\n",
    "\n",
    "# # Sparse kernel, optimize species with gradients, weights with linear algebra\n",
    "# mixed_species_model = MixedSpeciesSparseGapModel(\n",
    "#     global_species, \n",
    "#     n_support=100,\n",
    "#     n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "#     zeta=1, \n",
    "#     lambdas=[1e-1, 1e-6],\n",
    "#     optimizable_weights=False,\n",
    "# )\n",
    "\n",
    "# # Linear regression, optimize everything with gradients\n",
    "# mixed_species_model = MixedSpeciesLinearModel(\n",
    "#     global_species, \n",
    "#     n_pseudo_species=N_PSEUDO_SPECIES, \n",
    "#     lambdas=[1e-3, 1e-6],\n",
    "#     optimizable_weights=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=512, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_data_gpu if device == \"cuda\" else collate_data_cpu\n",
    ")\n",
    "\n",
    "# dataloader without batching for the initial fit\n",
    "train_dataloader_no_batch_cpu = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=len(train_dataset), \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_data_cpu\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_data_gpu if device == \"cuda\" else collate_data_cpu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_optimizer(predicted, actual, regularizer, weights):\n",
    "    loss = torch.linalg.norm(predicted - actual) ** 2\n",
    "    # regularize the loss, full dataset std\n",
    "    loss += regularizer / torch.std(train_energies) * torch.linalg.norm(weights) ** 2\n",
    "\n",
    "    # TODO alternative: batch std\n",
    "    # loss += regularizer / torch.std(actual) * torch.linalg.norm(weights) ** 2\n",
    "    return loss\n",
    "\n",
    "def loss_mae(predicted, actual):\n",
    "    return torch.mean(torch.abs(predicted - actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixed_species_model.optimizable_weights:\n",
    "    with torch.no_grad():\n",
    "        # initialize the weights to a nice value using fit\n",
    "        for spherical_expansions, species, slices, energies in train_dataloader_no_batch_cpu:\n",
    "            # we want to intially train the model on all frames, to ensure the\n",
    "            # support points come from the full dataset. This happens on CPU, the\n",
    "            # move to GPU is happening below\n",
    "            assert len(slices) == len(train_frames)\n",
    "            mixed_species_model.fit(spherical_expansions, species, slices, energies)\n",
    "\n",
    "\n",
    "if not mixed_species_model.optimizable_weights:\n",
    "    # we can not use batches if we are training with linear algebra, we need to\n",
    "    # have all training frames available\n",
    "    assert train_dataloader.batch_size >= len(train_frames)\n",
    "\n",
    "mixed_species_model.to(device=device)\n",
    "\n",
    "if mixed_species_model.optimizable_weights:\n",
    "    regularizer = 2e-3\n",
    "else:\n",
    "    regularizer = 0\n",
    "\n",
    "lrate = 0.1\n",
    "optimizer = torch.optim.AdamW(mixed_species_model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 took 0.3083s, optimizer loss=5.065e+07, test mae=465.7\n",
      "epoch 1 took 0.2928s, optimizer loss=1.906e+07, test mae=245.6\n",
      "epoch 2 took 0.2935s, optimizer loss=5.522e+06, test mae=120.1\n",
      "epoch 3 took 0.2939s, optimizer loss=1.484e+06, test mae=46.24\n",
      "epoch 4 took 0.2931s, optimizer loss=2.751e+05, test mae=11.51\n",
      "epoch 5 took 0.2934s, optimizer loss=2.236e+04, test mae=41.96\n",
      "epoch 6 took 0.2905s, optimizer loss=1.723e+05, test mae=71.68\n",
      "epoch 7 took 0.2926s, optimizer loss=4.958e+05, test mae=94.81\n",
      "epoch 8 took 0.2913s, optimizer loss=8.673e+05, test mae=112.0\n",
      "epoch 9 took 0.2905s, optimizer loss=1.204e+06, test mae=123.5\n",
      "epoch 10 took 0.29s, optimizer loss=1.454e+06, test mae=129.8\n",
      "epoch 11 took 0.2918s, optimizer loss=1.589e+06, test mae=131.4\n",
      "epoch 12 took 0.2922s, optimizer loss=1.607e+06, test mae=129.0\n",
      "epoch 13 took 0.2893s, optimizer loss=1.526e+06, test mae=123.3\n",
      "epoch 14 took 0.288s, optimizer loss=1.374e+06, test mae=115.0\n",
      "epoch 15 took 0.2901s, optimizer loss=1.182e+06, test mae=104.9\n",
      "epoch 16 took 0.2894s, optimizer loss=9.765e+05, test mae=93.62\n",
      "epoch 17 took 0.2918s, optimizer loss=7.763e+05, test mae=81.61\n",
      "epoch 18 took 0.2932s, optimizer loss=5.946e+05, test mae=69.3\n",
      "epoch 19 took 0.2909s, optimizer loss=4.383e+05, test mae=57.02\n",
      "epoch 20 took 0.2917s, optimizer loss=3.104e+05, test mae=44.99\n",
      "epoch 21 took 0.2931s, optimizer loss=2.11e+05, test mae=33.42\n",
      "epoch 22 took 0.2909s, optimizer loss=1.385e+05, test mae=23.19\n",
      "epoch 23 took 0.2919s, optimizer loss=9.033e+04, test mae=19.41\n",
      "epoch 24 took 0.2899s, optimizer loss=6.31e+04, test mae=19.79\n",
      "epoch 25 took 0.291s, optimizer loss=5.301e+04, test mae=21.54\n",
      "epoch 26 took 0.2897s, optimizer loss=5.598e+04, test mae=23.92\n",
      "epoch 27 took 0.2899s, optimizer loss=6.788e+04, test mae=26.71\n",
      "epoch 28 took 0.2909s, optimizer loss=8.472e+04, test mae=29.51\n",
      "epoch 29 took 0.2906s, optimizer loss=1.03e+05, test mae=32.01\n",
      "epoch 30 took 0.2915s, optimizer loss=1.196e+05, test mae=33.81\n",
      "epoch 31 took 0.2907s, optimizer loss=1.325e+05, test mae=35.02\n",
      "epoch 32 took 0.2885s, optimizer loss=1.402e+05, test mae=35.52\n",
      "epoch 33 took 0.2897s, optimizer loss=1.422e+05, test mae=35.21\n",
      "epoch 34 took 0.2929s, optimizer loss=1.388e+05, test mae=34.19\n",
      "epoch 35 took 0.2916s, optimizer loss=1.308e+05, test mae=32.61\n",
      "epoch 36 took 0.2911s, optimizer loss=1.193e+05, test mae=30.72\n",
      "epoch 37 took 0.2896s, optimizer loss=1.057e+05, test mae=28.62\n",
      "epoch 38 took 0.2901s, optimizer loss=9.145e+04, test mae=26.3\n",
      "epoch 39 took 0.2893s, optimizer loss=7.763e+04, test mae=23.97\n",
      "epoch 40 took 0.2891s, optimizer loss=6.522e+04, test mae=21.91\n",
      "epoch 41 took 0.2898s, optimizer loss=5.483e+04, test mae=19.98\n",
      "epoch 42 took 0.2902s, optimizer loss=4.675e+04, test mae=18.34\n",
      "epoch 43 took 0.2901s, optimizer loss=4.099e+04, test mae=17.14\n",
      "epoch 44 took 0.2926s, optimizer loss=3.729e+04, test mae=16.29\n",
      "epoch 45 took 0.2914s, optimizer loss=3.527e+04, test mae=15.51\n",
      "epoch 46 took 0.2907s, optimizer loss=3.444e+04, test mae=14.79\n",
      "epoch 47 took 0.2914s, optimizer loss=3.431e+04, test mae=14.3\n",
      "epoch 48 took 0.2917s, optimizer loss=3.442e+04, test mae=14.3\n",
      "epoch 49 took 0.2906s, optimizer loss=3.442e+04, test mae=14.29\n",
      "epoch 50 took 0.2918s, optimizer loss=3.404e+04, test mae=14.27\n",
      "epoch 51 took 0.2897s, optimizer loss=3.314e+04, test mae=14.18\n",
      "epoch 52 took 0.2933s, optimizer loss=3.167e+04, test mae=13.94\n",
      "epoch 53 took 0.2908s, optimizer loss=2.969e+04, test mae=13.58\n",
      "epoch 54 took 0.2903s, optimizer loss=2.733e+04, test mae=13.09\n",
      "epoch 55 took 0.2924s, optimizer loss=2.472e+04, test mae=12.53\n",
      "epoch 56 took 0.2911s, optimizer loss=2.205e+04, test mae=11.98\n",
      "epoch 57 took 0.2917s, optimizer loss=1.948e+04, test mae=11.56\n",
      "epoch 58 took 0.2892s, optimizer loss=1.713e+04, test mae=11.22\n",
      "epoch 59 took 0.2922s, optimizer loss=1.511e+04, test mae=10.9\n",
      "epoch 60 took 0.2904s, optimizer loss=1.346e+04, test mae=10.62\n",
      "epoch 61 took 0.2909s, optimizer loss=1.222e+04, test mae=10.54\n",
      "epoch 62 took 0.2888s, optimizer loss=1.134e+04, test mae=10.55\n",
      "epoch 63 took 0.2918s, optimizer loss=1.078e+04, test mae=10.6\n",
      "epoch 64 took 0.2923s, optimizer loss=1.047e+04, test mae=10.64\n",
      "epoch 65 took 0.2932s, optimizer loss=1.032e+04, test mae=10.66\n",
      "epoch 66 took 0.2934s, optimizer loss=1.027e+04, test mae=10.64\n",
      "epoch 67 took 0.2889s, optimizer loss=1.023e+04, test mae=10.6\n",
      "epoch 68 took 0.2931s, optimizer loss=1.016e+04, test mae=10.52\n",
      "epoch 69 took 0.2914s, optimizer loss=1.002e+04, test mae=10.42\n",
      "epoch 70 took 0.2899s, optimizer loss=9.796e+03, test mae=10.29\n",
      "epoch 71 took 0.292s, optimizer loss=9.492e+03, test mae=10.13\n",
      "epoch 72 took 0.2908s, optimizer loss=9.121e+03, test mae=9.959\n",
      "epoch 73 took 0.2873s, optimizer loss=8.707e+03, test mae=9.773\n",
      "epoch 74 took 0.2909s, optimizer loss=8.278e+03, test mae=9.607\n",
      "epoch 75 took 0.2911s, optimizer loss=7.861e+03, test mae=9.46\n",
      "epoch 76 took 0.2907s, optimizer loss=7.479e+03, test mae=9.326\n",
      "epoch 77 took 0.291s, optimizer loss=7.15e+03, test mae=9.195\n",
      "epoch 78 took 0.2931s, optimizer loss=6.88e+03, test mae=9.07\n",
      "epoch 79 took 0.2932s, optimizer loss=6.671e+03, test mae=8.956\n",
      "epoch 80 took 0.2911s, optimizer loss=6.518e+03, test mae=8.873\n",
      "epoch 81 took 0.2924s, optimizer loss=6.408e+03, test mae=8.823\n",
      "epoch 82 took 0.2905s, optimizer loss=6.33e+03, test mae=8.791\n",
      "epoch 83 took 0.291s, optimizer loss=6.267e+03, test mae=8.764\n",
      "epoch 84 took 0.2915s, optimizer loss=6.208e+03, test mae=8.74\n",
      "epoch 85 took 0.2914s, optimizer loss=6.142e+03, test mae=8.715\n",
      "epoch 86 took 0.2899s, optimizer loss=6.062e+03, test mae=8.69\n",
      "epoch 87 took 0.2911s, optimizer loss=5.965e+03, test mae=8.664\n",
      "epoch 88 took 0.2908s, optimizer loss=5.852e+03, test mae=8.64\n",
      "epoch 89 took 0.2917s, optimizer loss=5.725e+03, test mae=8.617\n",
      "epoch 90 took 0.2924s, optimizer loss=5.591e+03, test mae=8.595\n",
      "epoch 91 took 0.2911s, optimizer loss=5.456e+03, test mae=8.573\n",
      "epoch 92 took 0.2907s, optimizer loss=5.323e+03, test mae=8.552\n",
      "epoch 93 took 0.2904s, optimizer loss=5.2e+03, test mae=8.531\n",
      "epoch 94 took 0.2912s, optimizer loss=5.088e+03, test mae=8.51\n",
      "epoch 95 took 0.2905s, optimizer loss=4.988e+03, test mae=8.489\n",
      "epoch 96 took 0.2892s, optimizer loss=4.902e+03, test mae=8.469\n",
      "epoch 97 took 0.2906s, optimizer loss=4.827e+03, test mae=8.447\n",
      "epoch 98 took 0.2898s, optimizer loss=4.76e+03, test mae=8.426\n",
      "epoch 99 took 0.2902s, optimizer loss=4.699e+03, test mae=8.405\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "fname = 'tr'+str(n_train)+'_ts1000_rg'+str(regularizer)+'_opttrue_sparsep_noupdate_lr_mean_lr'+str(lrate)\n",
    "\n",
    "f = open(fname,'a+')\n",
    "f.write(f\"#epoch loss mae_test(eV/structure) {datetime.now()}\\n\")\n",
    "f.close()\n",
    "f = open(fname,'a+')\n",
    "\n",
    "all_losses = []\n",
    "for epoch in range(100):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    if UPDATE_SUPPORT_POINTS:\n",
    "        # to update the support points, we need to move to CPU to be able to fit\n",
    "        # all training data at once in memory\n",
    "        mixed_species_model.to(device=\"cpu\")\n",
    "        for spherical_expansions, species, slices, _ in train_dataloader_no_batch_cpu:\n",
    "            assert len(slices) == len(train_frames)\n",
    "            # use `select_again=True` to re-select the same number of support\n",
    "            # points. this might make convergence slower, but maybe able to\n",
    "            # reach a lower final loss?\n",
    "            #\n",
    "            # with `select_again=False`, the environments selected in the first\n",
    "            # fit above are used as support points\n",
    "            mixed_species_model.update_support_points(\n",
    "                spherical_expansions, species, select_again=False\n",
    "            )\n",
    "        mixed_species_model.to(device=device)\n",
    "\n",
    "    for spherical_expansions, species, slices, energies in train_dataloader:\n",
    "        def single_step():\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            if not mixed_species_model.optimizable_weights:\n",
    "                mixed_species_model.fit(spherical_expansions, species, slices, energies)\n",
    "                \n",
    "            predicted = mixed_species_model(spherical_expansions, species, slices)    \n",
    "\n",
    "            loss = loss_optimizer(predicted, energies, regularizer, mixed_species_model.model.weights)\n",
    "            loss.backward()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(single_step)\n",
    "        all_losses.append(loss.item())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            predicted = []\n",
    "            for spherical_expansions, species, slices, energies in test_dataloader:\n",
    "                predicted.append(mixed_species_model(spherical_expansions, species, slices))\n",
    "\n",
    "            predicted = torch.vstack(predicted)\n",
    "            mae = loss_mae(predicted.cpu(), test_dataset.energies)\n",
    "            f.write(f\"{epoch} {loss.item():.4} {mae:.4} {datetime.now()}\\n\")\n",
    "            f.close()\n",
    "            f = open(fname,'a+')\n",
    "\n",
    "        print(f\"epoch {epoch} took {epoch_time:.4}s, optimizer loss={loss.item():.4}, test mae={mae:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8ff6e88e50>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f93d8ca02d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "species_combining_matrix = mixed_species_model.alchemical.combining_matrix.detach().cpu().numpy()\n",
    "\n",
    "plt.scatter(species_combining_matrix[:, 0], species_combining_matrix[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for spherical_expansions, species, slices, energies in test_dataloader:\n",
    "    predicted.append(mixed_species_model(spherical_expansions, species, slices))\n",
    "\n",
    "predicted = torch.vstack(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8ff6b52210>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_dataset.energies, predicted.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ef12eb5922cf8d604aeb1dfa412e3da3665f54b5e701463f21d300328cee18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
