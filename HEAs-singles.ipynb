{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cProfile\n",
    "import time\n",
    "\n",
    "import ase.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import torch\n",
    "\n",
    "from utils.combine import CombineRadial, CombineRadialSpecies, CombineSpecies\n",
    "from utils.dataset import AtomisticDataset, create_dataloader\n",
    "from utils.linear import LinearModel\n",
    "from utils.operations import SumStructures, remove_gradient\n",
    "from utils.soap import PowerSpectrum\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 100 training frames\n"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "n_train = 100\n",
    "\n",
    "frames = ase.io.read(\"data/data_shuffle.xyz\", f\":{n_test + n_train}\")\n",
    "\n",
    "train_frames = frames[:n_train]\n",
    "test_frames = frames[-n_test:]\n",
    "\n",
    "train_energies = torch.tensor(\n",
    "    [frame.info[\"energy\"] for frame in train_frames]\n",
    ").reshape(-1, 1).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "test_energies = torch.tensor(\n",
    "    [frame.info[\"energy\"] for frame in test_frames]\n",
    ").reshape(-1, 1).to(dtype=torch.get_default_dtype())\n",
    "\n",
    "train_forces = [\n",
    "    torch.tensor(frame.arrays[\"forces\"]).to(dtype=torch.get_default_dtype())\n",
    "    for frame in train_frames\n",
    "]\n",
    "\n",
    "test_forces = [\n",
    "    torch.tensor(frame.arrays[\"forces\"]).to(dtype=torch.get_default_dtype()) \n",
    "    for frame in test_frames\n",
    "]\n",
    "\n",
    "print(f\"using {n_train} training frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = set()\n",
    "for frame in frames:\n",
    "    all_species.update(frame.numbers)\n",
    "\n",
    "all_species = list(map(lambda u: int(u), all_species))\n",
    "\n",
    "# HYPERS_FROM_PAPER = {\n",
    "#     \"interaction_cutoff\": 5.0,\n",
    "#     \"max_angular\": 9,\n",
    "#     \"max_radial\": 12,\n",
    "#     \"gaussian_sigma_constant\": 0.3,\n",
    "#     \"gaussian_sigma_type\": \"Constant\",\n",
    "#     \"cutoff_smooth_width\": 0.5,\n",
    "#     \"radial_basis\": \"GTO\",\n",
    "#     \"compute_gradients\": False,\n",
    "#     \"expansion_by_species_method\": \"user defined\",\n",
    "#     \"global_species\": all_species,\n",
    "# }\n",
    "\n",
    "HYPERS_SMALL = {\n",
    "    \"cutoff\": 4.0,\n",
    "    \"max_angular\": 0,\n",
    "    \"max_radial\": 12,\n",
    "    \"atomic_gaussian_width\": 0.3,\n",
    "    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n",
    "    \"radial_basis\": {\"SplinedGto\": {\"accuracy\": 1e-6}},\n",
    "    \"gradients\": False,\n",
    "    \"center_atom_weight\" : 0,\n",
    "    # # TODO: implement this in rascaline itself\n",
    "    # \"radial_per_angular\": {\n",
    "    #     # l: n\n",
    "    #     0: 10,\n",
    "    #     1: 8,\n",
    "    #     2: 8,\n",
    "    #     3: 4,\n",
    "    #     4: 4,\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Descriptor' object has no attribute 'keys_to_properties'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a982d68a7dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcalculator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSphericalExpansion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mHYPERS_SMALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"species_neighbor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Descriptor' object has no attribute 'keys_to_properties'"
     ]
    }
   ],
   "source": [
    "from rascaline import SphericalExpansion\n",
    "calculator = SphericalExpansion(**HYPERS_SMALL)\n",
    "descriptor = calculator.compute(frames)\n",
    "descriptor.keys_to_properties([\"species_neighbor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_species = np.unique(descriptor.keys['species_center'])\n",
    "my_species = { sp:i for i,sp in enumerate(my_species)  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 74 is out of bounds for axis 1 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2cea94d266e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'structure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_species\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 74 is out of bounds for axis 1 with size 25"
     ]
    }
   ],
   "source": [
    "X1 = np.zeros((len(frames), len(my_species)))\n",
    "for key, block in descriptor:\n",
    "    _, specie = key\n",
    "    idx, cnt = np.unique(block.samples['structure'], return_counts=True)    \n",
    "    X1[idx,all_species[specie]] += cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray([f.info['energy'] for f in frames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas=np.geomspace(1e-5,1e3,13), cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X[:n_train], y[:n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = ridge.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y[n_train:],yp[n_train:], \"r.\")\n",
    "plt.plot(y[:n_train],yp[:n_train], \"b.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.abs(y-yp)[n_train:]))/len(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-baf6c3de047a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge.coef_[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a8605241506e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(y, X1@ridge.coef_[:25], 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop, energies only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AtomisticDataset(train_frames, all_species, HYPERS_SMALL, train_energies, radial_spectrum_n_max=12)\n",
    "test_dataset = AtomisticDataset(train_frames, all_species, HYPERS_SMALL, train_energies, radial_spectrum_n_max=12)\n",
    "\n",
    "HYPERS_GRAD = copy.deepcopy(HYPERS_SMALL)\n",
    "HYPERS_GRAD[\"gradients\"] = False\n",
    "train_dataset_grad = AtomisticDataset(train_frames, all_species, HYPERS_GRAD, train_energies, train_forces)\n",
    "test_dataset_grad = AtomisticDataset(test_frames, all_species, HYPERS_GRAD, test_energies, test_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_no_batch = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=len(train_dataset),\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_single_frame = create_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_grad = create_dataloader(\n",
    "    train_dataset_grad,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_dataloader_grad_no_batch = create_dataloader(\n",
    "    train_dataset_grad,\n",
    "    batch_size=len(train_dataset_grad),\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataloader = create_dataloader(\n",
    "    test_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataloader_grad = create_dataloader(\n",
    "    test_dataset_grad,\n",
    "    batch_size=50,\n",
    "    shuffle=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_optimizer(predicted, actual, regularizer, weights):\n",
    "    loss = torch.linalg.norm(predicted.flatten() - actual.flatten()) ** 2\n",
    "    # regularize the loss, full dataset std\n",
    "    loss += regularizer / torch.std(train_energies.flatten()) * torch.linalg.norm(weights) ** 2\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_optimizer_forces(predicted, actual, predicted_f, actual_f, regularizer, weights):\n",
    "    loss = torch.linalg.norm(predicted.flatten() - actual.flatten()) ** 2\n",
    "    loss += torch.linalg.norm(predicted_f.flatten() - actual_f.flatten()) ** 2\n",
    "    # regularize the loss, full dataset std\n",
    "    loss += regularizer / torch.std(train_energies.flatten()) * torch.linalg.norm(weights) ** 2\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_mae(predicted, actual):\n",
    "    return torch.mean(torch.abs(predicted.flatten() - actual.flatten()))\n",
    "\n",
    "def loss_rmse(predicted, actual):\n",
    "    return torch.sqrt(torch.mean((predicted.flatten() - actual.flatten())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionFeatures(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        all_species\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.species_dict = {s:i for i,s in enumerate(all_species)}    \n",
    "    \n",
    "    def forward(self, frames):\n",
    "        \n",
    "        X = torch.zeros(size=(len(frames), len(self.species_dict)))\n",
    "        for i, f in enumerate(frames):\n",
    "            for s in f.numbers:\n",
    "                X[i,self.species_dict[s]] += 1\n",
    "        return X       \n",
    "\n",
    "class CompositionLinearModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        all_species,\n",
    "        regularizer,\n",
    "        random_initial_weights=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.composition = CompositionFeatures(all_species)\n",
    "        \n",
    "        self.random_initial_weights = random_initial_weights\n",
    "        if random_initial_weights:\n",
    "            el_weights = torch.rand((len(all_species), 1), device=device)\n",
    "        else:\n",
    "            el_weights = torch.zeros((len(all_species), 1), device=device)\n",
    "        self.weights = torch.nn.Parameter(el_weights.detach() )\n",
    "\n",
    "    def forward(self, frames):\n",
    "                \n",
    "        energies = self.composition(frames)@self.weights\n",
    "        return energies, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_REGULARIZER = 1e-2\n",
    "\n",
    "model = CompositionLinearModel(\n",
    "    all_species=all_species,\n",
    "    # combiner=combiner, \n",
    "    regularizer=TORCH_REGULARIZER,\n",
    "    random_initial_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompositionLinearModel(\n",
       "  (composition): CompositionFeatures()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=device, dtype=torch.get_default_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=lr, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "filename = f\"{model.__class__.__name__}-composition-{n_train}-train\"\n",
    "\n",
    "if model.random_initial_weights:\n",
    "    filename += \"-random-weights\"\n",
    "\n",
    "output = open(f\"{filename}.dat\", \"w\")\n",
    "output.write(\"# epoch  train_loss  test_mae\\n\")\n",
    "n_epochs_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.6105], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([13.4637], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([12.1423], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-1.0713], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-133.2073], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-145.4297], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-255.4315], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-254.4812], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-245.9285], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-243.0608], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-217.2522], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-216.9958], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-214.6882], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-214.4437], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-212.2432], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-213.0745], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-213.5710], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.0400], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.1140], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7798], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7751], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7641], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7651], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7489], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "tensor([-218.7587], grad_fn=<SelectBackward0>) tensor([-218.6154])\n",
      "epoch 0 took 1.578s, optimizer loss=1.141e+07, test mae=8.849\n",
      "tensor([-421.2382], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2217], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2418], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2343], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2439], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2418], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2468], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2466], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2497], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2502], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2522], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2529], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2544], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2550], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2561], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2567], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2576], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2580], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2588], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2591], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "tensor([-421.2597], grad_fn=<SelectBackward0>) tensor([-428.4615])\n",
      "epoch 1 took 1.103s, optimizer loss=1.286e+04, test mae=8.832\n",
      "tensor([-410.6836], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6810], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6789], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6768], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6751], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6734], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6721], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6707], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6696], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6684], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6676], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6666], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6659], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6652], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6646], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6640], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6635], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6630], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6626], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6623], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "tensor([-410.6619], grad_fn=<SelectBackward0>) tensor([-418.5530])\n",
      "epoch 2 took 1.173s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-341.1572], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1568], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1566], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1562], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1560], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1557], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1556], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1553], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1552], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1550], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1549], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1548], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1547], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1546], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1545], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1544], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1543], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1542], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1542], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1541], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "tensor([-341.1541], grad_fn=<SelectBackward0>) tensor([-337.4752])\n",
      "epoch 3 took 1.208s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-308.5666], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5666], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5666], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5667], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5667], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5667], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5667], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5667], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "tensor([-308.5668], grad_fn=<SelectBackward0>) tensor([-315.9908])\n",
      "epoch 4 took 1.282s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "tensor([-343.6971], grad_fn=<SelectBackward0>) tensor([-342.1561])\n",
      "epoch 5 took 1.204s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-258.8968], grad_fn=<SelectBackward0>) tensor([-269.1560])\n",
      "tensor([-258.8968], grad_fn=<SelectBackward0>) tensor([-269.1560])\n",
      "epoch 6 took 0.182s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-160.3065], grad_fn=<SelectBackward0>) tensor([-168.3100])\n",
      "tensor([-160.3065], grad_fn=<SelectBackward0>) tensor([-168.3100])\n",
      "epoch 7 took 0.2089s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-323.3347], grad_fn=<SelectBackward0>) tensor([-314.0348])\n",
      "tensor([-323.3347], grad_fn=<SelectBackward0>) tensor([-314.0348])\n",
      "epoch 8 took 0.2009s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-256.4456], grad_fn=<SelectBackward0>) tensor([-266.6103])\n",
      "tensor([-256.4456], grad_fn=<SelectBackward0>) tensor([-266.6103])\n",
      "epoch 9 took 0.2214s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-515.5136], grad_fn=<SelectBackward0>) tensor([-498.7814])\n",
      "tensor([-515.5136], grad_fn=<SelectBackward0>) tensor([-498.7814])\n",
      "epoch 10 took 0.2288s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-259.3030], grad_fn=<SelectBackward0>) tensor([-276.5777])\n",
      "tensor([-259.3030], grad_fn=<SelectBackward0>) tensor([-276.5777])\n",
      "epoch 11 took 0.2105s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-259.3030], grad_fn=<SelectBackward0>) tensor([-276.5777])\n",
      "tensor([-259.3030], grad_fn=<SelectBackward0>) tensor([-276.5777])\n",
      "epoch 12 took 0.228s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-279.3699], grad_fn=<SelectBackward0>) tensor([-291.6979])\n",
      "tensor([-279.3699], grad_fn=<SelectBackward0>) tensor([-291.6979])\n",
      "epoch 13 took 0.2184s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-254.8097], grad_fn=<SelectBackward0>) tensor([-262.0550])\n",
      "tensor([-254.8097], grad_fn=<SelectBackward0>) tensor([-262.0550])\n",
      "epoch 14 took 0.2187s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-318.7922], grad_fn=<SelectBackward0>) tensor([-311.2183])\n",
      "tensor([-318.7922], grad_fn=<SelectBackward0>) tensor([-311.2183])\n",
      "epoch 15 took 0.2178s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-318.7922], grad_fn=<SelectBackward0>) tensor([-311.2183])\n",
      "epoch 16 took 0.1582s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-159.7991], grad_fn=<SelectBackward0>) tensor([-158.8192])\n",
      "epoch 17 took 0.1655s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-173.9018], grad_fn=<SelectBackward0>) tensor([-182.5398])\n",
      "epoch 18 took 0.1528s, optimizer loss=1.286e+04, test mae=8.83\n",
      "tensor([-231.8436], grad_fn=<SelectBackward0>) tensor([-224.5598])\n",
      "epoch 19 took 0.1765s, optimizer loss=1.286e+04, test mae=8.83\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    for frame, _, _, energies, _ in train_dataloader:\n",
    "        def single_step():\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            predicted, _ = model(frame)\n",
    "            print(predicted[0], energies[0])\n",
    "            loss = loss_optimizer(\n",
    "                predicted, \n",
    "                energies, \n",
    "                TORCH_REGULARIZER, \n",
    "                model.weights\n",
    "            )\n",
    "            loss.backward(retain_graph=False)\n",
    "\n",
    "            return loss\n",
    "            \n",
    "        loss = optimizer.step(single_step)\n",
    "        loss = loss.item()\n",
    "        all_losses.append(loss)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            predicted = []\n",
    "            reference = []\n",
    "            for frame, _, _, energies, _ in test_dataloader:\n",
    "                reference.append(energies)\n",
    "                predicted_e, _ = model(frame)\n",
    "                predicted.append(predicted_e)\n",
    "\n",
    "            reference = torch.vstack(reference)\n",
    "            predicted = torch.vstack(predicted)\n",
    "            mae = loss_mae(predicted, reference)\n",
    "\n",
    "            output.write(f\"{n_epochs_total} {loss} {mae}\\n\")\n",
    "            output.flush()\n",
    "\n",
    "        print(f\"epoch {n_epochs_total} took {epoch_time:.4}s, optimizer loss={loss:.4}, test mae={mae:.4}\")\n",
    "    \n",
    "    del frame, loss, mae\n",
    "        \n",
    "    n_epochs_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23419cf400>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predicted, energies, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting forces with forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_forces(model, dataloader):\n",
    "    predicted_e = []\n",
    "    reference_e = []\n",
    "    predicted_f = []\n",
    "    reference_f = []\n",
    "    for spherical_expansions, energies, forces in dataloader:\n",
    "        reference_e.append(energies)\n",
    "        reference_f.append(forces)\n",
    "        e, f = model(spherical_expansions, forward_forces=True)\n",
    "        predicted_e.append(e)\n",
    "        predicted_f.append(f)\n",
    "\n",
    "    reference_e = torch.vstack(reference_e)\n",
    "    predicted_e = torch.vstack(predicted_e)\n",
    "\n",
    "    reference_f = torch.vstack(reference_f)\n",
    "    predicted_f = torch.vstack(predicted_f)\n",
    "\n",
    "    return reference_e, predicted_e, reference_f, predicted_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_plots(reference_e, predicted_e, reference_f, predicted_f):\n",
    "    predicted_e = predicted_e.detach()\n",
    "    predicted_f = predicted_f.detach()\n",
    "\n",
    "    fig, (ax_e, ax_f) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    mae = loss_mae(predicted_e, reference_e)\n",
    "    rmse = loss_rmse(predicted_e, reference_e)\n",
    "    ax_e.scatter(reference_e.cpu(), predicted_e.cpu())\n",
    "    x = (torch.min(reference_e.flatten()).item(), torch.max(reference_e.flatten()).item())\n",
    "    ax_e.plot(x, x, color=\"red\")\n",
    "    ax_e.set_title(f\"energies, MAE={mae:.4}, RMSE={rmse:.4}\")\n",
    "    ax_e.set_xlabel(\"actual\")\n",
    "    ax_e.set_ylabel(\"predicted\")\n",
    "\n",
    "    mae = loss_mae(predicted_f, reference_f)\n",
    "    rmse = loss_rmse(predicted_f, reference_f)\n",
    "    ax_f.scatter(reference_f.cpu(), predicted_f.cpu())\n",
    "    x = (torch.min(reference_f.flatten()).item(), torch.max(reference_f.flatten()).item())\n",
    "    ax_f.plot(x, x, color=\"red\")\n",
    "    ax_f.set_title(f\"forces, MAE={mae:.4}, RMSE={rmse:.4}\")\n",
    "    ax_f.set_xlabel(\"actual\")\n",
    "    ax_f.set_ylabel(\"predicted\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = parity_plots(*evaluate_model_with_forces(model, test_dataloader_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_finite_differences(model, frame, delta=1e-6):\n",
    "    frame = frame.copy()\n",
    "    delta_frame = frame.copy()\n",
    "    delta_frame.positions[3, 1] += delta\n",
    "\n",
    "    dataset = AtomisticDataset([frame, delta_frame], all_species, HYPERS_GRAD, torch.zeros(2, 1))\n",
    "    dataloader = create_dataloader(\n",
    "        dataset,\n",
    "        batch_size=len(dataset),\n",
    "        shuffle=False,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    for spherical_expansion, _, _ in dataloader:\n",
    "        predicted_e, predicted_f = model(spherical_expansion, forward_forces=True)\n",
    "\n",
    "    finite_diff = - (predicted_e[1] - predicted_e[0]) / delta\n",
    "    print(\"finite difference =\", finite_diff.item())\n",
    "    print(\"computed gradient =\", predicted_f[3, 1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.get_default_dtype() == torch.float64:\n",
    "    delta = 1e-6\n",
    "else:\n",
    "    delta = 1e-3\n",
    "\n",
    "check_finite_differences(model, train_frames[22], delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with forces, linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_algebra_model = CombinedLinearModel(\n",
    "    combiner=model.combiner.detach(),\n",
    "    regularizer=[LINALG_REGULARIZER_ENERGIES, LINALG_REGULARIZER_FORCES],\n",
    "    optimizable_weights=False,\n",
    "    random_initial_weights=False, # <<<<==== VERY IMPORTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for spherical_expansions, energies, forces in train_dataloader_grad_no_batch:\n",
    "        linear_algebra_model.initialize_model_weights(spherical_expansions, energies, forces)\n",
    "\n",
    "del spherical_expansions, energies, forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = parity_plots(*evaluate_model_with_forces(\n",
    "    linear_algebra_model, test_dataloader_grad\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization loop, energies and forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    for spherical_expansions, energies, forces in train_dataloader_grad:\n",
    "        def single_step():\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            assert model.optimizable_weights\n",
    "            predicted_e, predicted_f = model(spherical_expansions, forward_forces=True)\n",
    "\n",
    "            loss = loss_optimizer_forces(\n",
    "                predicted_e,\n",
    "                energies,\n",
    "                predicted_f,\n",
    "                forces,\n",
    "                torch_loss_regularizer,\n",
    "                model.model.weights\n",
    "            )\n",
    "            loss.backward(retain_graph=False)\n",
    "\n",
    "            return loss\n",
    "            \n",
    "        loss = optimizer.step(single_step)\n",
    "        loss = loss.item()\n",
    "        all_losses.append(loss)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            for spherical_expansions, energies, _ in test_dataloader:\n",
    "                predicted_e, _ = model(spherical_expansions, forward_forces=False)\n",
    "\n",
    "            mae = loss_mae(predicted_e, energies)            \n",
    "\n",
    "            output.write(f\"{n_epochs_total} {loss} {mae}\\n\")\n",
    "            output.flush()\n",
    "\n",
    "        print(f\"epoch {n_epochs_total} took {epoch_time:.4}s, optimizer loss={loss:.4}, test mae={mae:.4}\")\n",
    "        \n",
    "    del spherical_expansions, mae, energies\n",
    "    n_epochs_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = parity_plots(*evaluate_model_with_forces(model, test_dataloader_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: predicting forces with backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fdb860dc9f423b713ecf03ec3bee4ef4df65400e892ebee65bf9175396f229c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
